{
 "cells": [
  {
   "cell_type": "raw",
   "id": "853e5f5f-49a3-4988-9876-968dfc5abcf6",
   "metadata": {},
   "source": [
    "#Q1\n",
    "To calculate the mean sales for each region, you need to sum up all the sales values for each region and then divide the sum by the number of data points (sales values) in that region. Let's do the calculations for Region A and Region B:\n",
    "\n",
    "Region A sales data: [10, 15, 12, 8, 14]\n",
    "\n",
    "Mean sales for Region A:\n",
    "Mean = (Sum of sales values in Region A) / (Number of sales values in Region A)\n",
    "Mean = (10 + 15 + 12 + 8 + 14) / 5\n",
    "Mean = 59 / 5\n",
    "Mean = 11.8\n",
    "\n",
    "So, the mean sales for Region A is 11.8.\n",
    "\n",
    "Region B sales data: [18, 20, 16, 22, 25]\n",
    "\n",
    "Mean sales for Region B:\n",
    "Mean = (Sum of sales values in Region B) / (Number of sales values in Region B)\n",
    "Mean = (18 + 20 + 16 + 22 + 25) / 5\n",
    "Mean = 101 / 5\n",
    "Mean = 20.2\n",
    "\n",
    "So, the mean sales for Region B is 20.2.\n",
    "\n",
    "To summarize:\n",
    "- Mean sales for Region A: 11.8\n",
    "- Mean sales for Region B: 20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2de7a5-b76f-4fec-9dcd-fb08a3622662",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2\n",
    "To calculate the mode of the survey responses, we need to find the value that appears most frequently in the data set. In this case, the data set is:\n",
    "\n",
    "[4, 5, 2, 3, 5, 4, 3, 2, 4, 5]\n",
    "\n",
    "Let's count the occurrences of each value:\n",
    "\n",
    "- 2 appears 2 times\n",
    "- 3 appears 2 times\n",
    "- 4 appears 3 times\n",
    "- 5 appears 3 times\n",
    "\n",
    "The mode is the value that appears most frequently. In this case, both 4 and 5 appear three times each, making them the modes of the survey responses. If there is more than one mode, it is called bimodal or multimodal. So, the mode of the survey responses is 4 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cd115-3ddf-46b7-97c6-9a1fbf674c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3\n",
    "To calculate the median salary for each department, you need to follow these steps:\n",
    "\n",
    "Step 1: Sort the salary data in ascending order.\n",
    "Step 2: Find the middle value of the sorted data. If the number of data points is odd, this will be the middle value. If the number of data points is even, the median will be the average of the two middle values.\n",
    "\n",
    "Let's go through the process for each department:\n",
    "\n",
    "Department A: [5000, 6000, 5500, 7000]\n",
    "\n",
    "Step 1: Sort the data in ascending order:\n",
    "[5000, 5500, 6000, 7000]\n",
    "\n",
    "Step 2: Find the median:\n",
    "Since there are an odd number of data points (4 in this case), the median is the middle value, which is 5500.\n",
    "\n",
    "So, the median salary for Department A is 5500.\n",
    "\n",
    "Department B: [4500, 5500, 5800, 6000, 5200]\n",
    "\n",
    "Step 1: Sort the data in ascending order:\n",
    "[4500, 5200, 5500, 5800, 6000]\n",
    "\n",
    "Step 2: Find the median:\n",
    "Since there are an odd number of data points (5 in this case), the median is the middle value, which is 5500.\n",
    "\n",
    "So, the median salary for Department B is 5500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae763c-35e7-43bd-9e64-a024d179ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4\n",
    "To calculate the range of the stock prices, you simply need to find the difference between the highest and lowest values in the dataset. Here's how you can do it step-by-step:\n",
    "\n",
    "Step 1: Arrange the data in ascending order (from lowest to highest):\n",
    "[24.8, 24.9, 25.3, 25.5, 26.1]\n",
    "\n",
    "Step 2: Find the highest and lowest values in the dataset:\n",
    "Lowest value = 24.8\n",
    "Highest value = 26.1\n",
    "\n",
    "Step 3: Calculate the range:\n",
    "Range = Highest value - Lowest value\n",
    "Range = 26.1 - 24.8\n",
    "Range = 1.3\n",
    "\n",
    "The range of the stock prices is 1.3. This value represents the variability in the daily stock prices of the company over the given period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21e1d4-13b6-4585-a5cd-4588dd27d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5\n",
    "To determine if there is a significant difference in the mean scores between Group A and Group B, we can perform a two-sample t-test. The t-test will help us assess whether the difference in the means of the two groups is statistically significant or if it could have occurred by chance.\n",
    "\n",
    "Here are the steps to perform the t-test:\n",
    "\n",
    "Step 1: State the hypotheses\n",
    "- Null Hypothesis (H0): There is no significant difference in the mean test scores between Group A and Group B.\n",
    "- Alternative Hypothesis (H1): There is a significant difference in the mean test scores between Group A and Group B.\n",
    "\n",
    "Step 2: Set the significance level (alpha)\n",
    "Let's assume a significance level (alpha) of 0.05, which is a common choice in statistical tests. This means we are willing to accept a 5% chance of making a Type I error (rejecting the null hypothesis when it is true).\n",
    "\n",
    "Step 3: Compute the t-test statistic\n",
    "The formula for the t-test statistic for independent samples (assuming equal variances) is:\n",
    "\n",
    "\\[ t = \\frac{{\\bar{X}_1 - \\bar{X}_2}}{SE} \\]\n",
    "\n",
    "where:\n",
    "- \\(\\bar{X}_1\\) and \\(\\bar{X}_2\\) are the sample means of Group A and Group B, respectively.\n",
    "- \\(SE\\) is the standard error of the difference between the means, which is calculated as:\n",
    "\n",
    "\\[ SE = \\sqrt{\\frac{{s_1^2}}{n_1} + \\frac{{s_2^2}}{n_2}} \\]\n",
    "\n",
    "where:\n",
    "- \\(s_1\\) and \\(s_2\\) are the sample standard deviations of Group A and Group B, respectively.\n",
    "- \\(n_1\\) and \\(n_2\\) are the sample sizes of Group A and Group B, respectively.\n",
    "\n",
    "Step 4: Determine the degrees of freedom (df)\n",
    "The degrees of freedom for the t-test for independent samples is calculated as:\n",
    "\n",
    "\\[ df = n_1 + n_2 - 2 \\]\n",
    "\n",
    "Step 5: Find the critical value and p-value\n",
    "Using the t-distribution table or statistical software, find the critical value and corresponding p-value for the calculated t-test statistic and degrees of freedom.\n",
    "\n",
    "Step 6: Compare the p-value with the significance level\n",
    "- If p-value â‰¤ alpha (0.05 in this case), reject the null hypothesis (H0) in favor of the alternative hypothesis (H1), indicating a significant difference in the mean test scores between the two groups.\n",
    "- If p-value > alpha (0.05 in this case), fail to reject the null hypothesis (H0), indicating no significant difference in the mean test scores between the two groups.\n",
    "\n",
    "Now, let's calculate the t-test in Python:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Data\n",
    "group_a_scores = np.array([85, 90, 92, 88, 91])\n",
    "group_b_scores = np.array([82, 88, 90, 86, 87])\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic, p_value = ttest_ind(group_a_scores, group_b_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "```\n",
    "\n",
    "Running this code will give you the t-test statistic and the p-value. Compare the p-value with the significance level (0.05) to determine whether there is a significant difference in the mean scores between Group A and Group B. If the p-value is less than or equal to 0.05, you can reject the null hypothesis and conclude that there is a significant difference in the mean scores. Otherwise, if the p-value is greater than 0.05, you fail to reject the null hypothesis, indicating no significant difference.B"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e8e461d-b5ed-4b60-97f6-92c4bf5b111c",
   "metadata": {},
   "source": [
    "Q6\n",
    "To calculate the correlation coefficient between advertising expenditure and sales, you can follow these steps:\n",
    "\n",
    "Step 1: Find the mean of both the advertising expenditure and sales data.\n",
    "Step 2: Calculate the difference between each data point and its respective mean for both advertising expenditure and sales.\n",
    "Step 3: Square each difference calculated in Step 2.\n",
    "Step 4: Sum up all the squared differences for both advertising expenditure and sales.\n",
    "Step 5: Multiply the sums obtained in Step 4 for both advertising expenditure and sales.\n",
    "Step 6: Calculate the square root of the product obtained in Step 5.\n",
    "Step 7: Divide the result from Step 5 by the result from Step 6 to get the correlation coefficient.\n",
    "\n",
    "Let's perform the calculations:\n",
    "\n",
    "Step 1: Find the mean of advertising expenditure and sales:\n",
    "\n",
    "Mean of Advertising Expenditure = (10 + 15 + 12 + 8 + 14) / 5 = 59 / 5 = 11.8 (thousands)\n",
    "\n",
    "Mean of Sales = (25 + 30 + 28 + 20 + 26) / 5 = 129 / 5 = 25.8 (thousands)\n",
    "\n",
    "Step 2: Calculate the difference between each data point and the mean:\n",
    "\n",
    "For Advertising Expenditure:\n",
    "[10 - 11.8, 15 - 11.8, 12 - 11.8, 8 - 11.8, 14 - 11.8] = [-1.8, 3.2, 0.2, -3.8, 2.2]\n",
    "\n",
    "For Sales:\n",
    "[25 - 25.8, 30 - 25.8, 28 - 25.8, 20 - 25.8, 26 - 25.8] = [-0.8, 4.2, 2.2, -5.8, 0.2]\n",
    "\n",
    "Step 3: Square each difference:\n",
    "\n",
    "For Advertising Expenditure:\n",
    "[(-1.8)^2, (3.2)^2, (0.2)^2, (-3.8)^2, (2.2)^2] = [3.24, 10.24, 0.04, 14.44, 4.84]\n",
    "\n",
    "For Sales:\n",
    "[(-0.8)^2, (4.2)^2, (2.2)^2, (-5.8)^2, (0.2)^2] = [0.64, 17.64, 4.84, 33.64, 0.04]\n",
    "\n",
    "Step 4: Sum up all the squared differences:\n",
    "\n",
    "Sum of squared differences for Advertising Expenditure = 3.24 + 10.24 + 0.04 + 14.44 + 4.84 = 33.8\n",
    "\n",
    "Sum of squared differences for Sales = 0.64 + 17.64 + 4.84 + 33.64 + 0.04 = 57.8\n",
    "\n",
    "Step 5: Multiply the sums of squared differences:\n",
    "\n",
    "Product = 33.8 * 57.8 = 1953.64\n",
    "\n",
    "Step 6: Calculate the square root of the product:\n",
    "\n",
    "âˆš(1953.64) â‰ˆ 44.18\n",
    "\n",
    "Step 7: Divide the result from Step 5 by the result from Step 6 to get the correlation coefficient:\n",
    "\n",
    "Correlation Coefficient = 1953.64 / 44.18 â‰ˆ 44.18\n",
    "\n",
    "So, the correlation coefficient between advertising expenditure and sales is approximately 44.18. Note that this value falls between -1 and 1, where 1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no correlation. In this case, the positive correlation indicates that as advertising expenditure increases, sales also tend to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f617f08-4e81-48f2-8aa1-5627a29aab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7\n",
    "To calculate the standard deviation of the heights, you can follow these steps:\n",
    "\n",
    "Step 1: Find the mean (average) of the heights.\n",
    "Step 2: Subtract the mean from each height to get the deviations from the mean.\n",
    "Step 3: Square each deviation.\n",
    "Step 4: Find the mean of the squared deviations.\n",
    "Step 5: Take the square root of the mean of squared deviations to get the standard deviation.\n",
    "\n",
    "Let's go through the calculations:\n",
    "\n",
    "Step 1: Find the mean (average) of the heights.\n",
    "Mean = (160 + 170 + 165 + 155 + 175 + 180 + 170) / 7\n",
    "Mean = 1275 / 7\n",
    "Mean â‰ˆ 182.14 (rounded to two decimal places)\n",
    "\n",
    "Step 2: Subtract the mean from each height to get the deviations from the mean.\n",
    "Deviation from mean = [160 - 182.14, 170 - 182.14, 165 - 182.14, 155 - 182.14, 175 - 182.14, 180 - 182.14, 170 - 182.14]\n",
    "Deviation from mean â‰ˆ [-22.14, -12.14, -17.14, -27.14, -7.14, -2.14, -12.14]\n",
    "\n",
    "Step 3: Square each deviation.\n",
    "Squared deviations â‰ˆ [488.9196, 147.5956, 293.0596, 735.8596, 51.0796, 4.5796, 147.5956]\n",
    "\n",
    "Step 4: Find the mean of the squared deviations.\n",
    "Mean of squared deviations = (488.9196 + 147.5956 + 293.0596 + 735.8596 + 51.0796 + 4.5796 + 147.5956) / 7\n",
    "Mean of squared deviations â‰ˆ 244.14 (rounded to two decimal places)\n",
    "\n",
    "Step 5: Take the square root of the mean of squared deviations to get the standard deviation.\n",
    "Standard deviation â‰ˆ âˆš244.14 â‰ˆ 15.62 (rounded to two decimal places)\n",
    "\n",
    "So, the standard deviation of the heights is approximately 15.62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d580f74-d873-40f9-b4e9-60d83fa5c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8\n",
    "To perform a linear regression analysis to predict job satisfaction based on employee tenure, we will use the collected data. Linear regression is a statistical method that helps us find the relationship between two variables and make predictions.\n",
    "\n",
    "First, let's organize the data:\n",
    "\n",
    "Employee Tenure (in years): [2, 3, 5, 4, 6, 2, 4]\n",
    "Job Satisfaction (on a scale of 1 to 10): [7, 8, 6, 9, 5, 7, 6]\n",
    "\n",
    "Step 1: Calculate the mean of both the Employee Tenure and Job Satisfaction data.\n",
    "\n",
    "Mean of Employee Tenure (X):\n",
    "XÌ„ = (2 + 3 + 5 + 4 + 6 + 2 + 4) / 7 = 26 / 7 â‰ˆ 3.71 (rounded to two decimal places)\n",
    "\n",
    "Mean of Job Satisfaction (Y):\n",
    "È² = (7 + 8 + 6 + 9 + 5 + 7 + 6) / 7 = 48 / 7 â‰ˆ 6.86 (rounded to two decimal places)\n",
    "\n",
    "Step 2: Calculate the Covariance and Variance of Employee Tenure and Job Satisfaction.\n",
    "\n",
    "Covariance (Cov) measures how two variables change together. It can be calculated as:\n",
    "\n",
    "Cov(X, Y) = Î£[(X - XÌ„) * (Y - È²)] / (n - 1)\n",
    "\n",
    "where Î£ is the summation symbol, n is the number of data points.\n",
    "\n",
    "Let's calculate the Covariance:\n",
    "\n",
    "Cov(X, Y) = [(2 - 3.71) * (7 - 6.86) + (3 - 3.71) * (8 - 6.86) + (5 - 3.71) * (6 - 6.86) + (4 - 3.71) * (9 - 6.86) + (6 - 3.71) * (5 - 6.86) + (2 - 3.71) * (7 - 6.86) + (4 - 3.71) * (6 - 6.86)] / (7 - 1)\n",
    "Cov(X, Y) â‰ˆ -0.86 (rounded to two decimal places)\n",
    "\n",
    "Variance of X (Var(X)):\n",
    "\n",
    "Var(X) = Î£[(X - XÌ„)^2] / (n - 1)\n",
    "\n",
    "Let's calculate the Variance of X:\n",
    "\n",
    "Var(X) = [(2 - 3.71)^2 + (3 - 3.71)^2 + (5 - 3.71)^2 + (4 - 3.71)^2 + (6 - 3.71)^2 + (2 - 3.71)^2 + (4 - 3.71)^2] / (7 - 1)\n",
    "Var(X) â‰ˆ 2.10 (rounded to two decimal places)\n",
    "\n",
    "Variance of Y (Var(Y)):\n",
    "\n",
    "Var(Y) = Î£[(Y - È²)^2] / (n - 1)\n",
    "\n",
    "Let's calculate the Variance of Y:\n",
    "\n",
    "Var(Y) = [(7 - 6.86)^2 + (8 - 6.86)^2 + (6 - 6.86)^2 + (9 - 6.86)^2 + (5 - 6.86)^2 + (7 - 6.86)^2 + (6 - 6.86)^2] / (7 - 1)\n",
    "Var(Y) â‰ˆ 2.10 (rounded to two decimal places)\n",
    "\n",
    "Step 3: Calculate the slope (Î²) of the regression line.\n",
    "\n",
    "Î² = Cov(X, Y) / Var(X)\n",
    "\n",
    "Î² â‰ˆ -0.86 / 2.10 â‰ˆ -0.41 (rounded to two decimal places)\n",
    "\n",
    "Step 4: Calculate the intercept (Î±) of the regression line.\n",
    "\n",
    "Î± = È² - Î² * XÌ„\n",
    "\n",
    "Î± â‰ˆ 6.86 - (-0.41 * 3.71) â‰ˆ 8.43 (rounded to two decimal places)\n",
    "\n",
    "Step 5: Formulate the regression equation.\n",
    "\n",
    "The regression equation is in the form of Y = Î± + Î² * X.\n",
    "\n",
    "Y â‰ˆ 8.43 - 0.41 * X\n",
    "\n",
    "Now, we have our regression equation: Job Satisfaction â‰ˆ 8.43 - 0.41 * Employee Tenure.\n",
    "\n",
    "This equation can be used to predict job satisfaction based on employee tenure in the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506bbab-551e-4476-ba14-4fb87b88c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9\n",
    "To perform an analysis of variance (ANOVA) to determine if there is a significant difference in the mean recovery times between Medication A and Medication B, follow these steps:\n",
    "\n",
    "Step 1: State the hypotheses:\n",
    "- Null hypothesis (H0): There is no significant difference in the mean recovery times between Medication A and Medication B.\n",
    "- Alternative hypothesis (Ha): There is a significant difference in the mean recovery times between Medication A and Medication B.\n",
    "\n",
    "Step 2: Calculate the mean recovery times for each group (Medication A and Medication B).\n",
    "\n",
    "Mean of Medication A (XÌ„A):\n",
    "   XÌ„A = (10 + 12 + 14 + 11 + 13) / 5\n",
    "   XÌ„A = 12\n",
    "\n",
    "Mean of Medication B (XÌ„B):\n",
    "   XÌ„B = (15 + 17 + 16 + 14 + 18) / 5\n",
    "   XÌ„B = 16\n",
    "\n",
    "Step 3: Calculate the overall mean (Grand Mean):\n",
    "\n",
    "Grand Mean (XÌ„G) = (XÌ„A + XÌ„B) / 2\n",
    "Grand Mean (XÌ„G) = (12 + 16) / 2\n",
    "Grand Mean (XÌ„G) = 14\n",
    "\n",
    "Step 4: Calculate the Sum of Squares Total (SST):\n",
    "\n",
    "SST = Î£ (Xi - XÌ„G)^2\n",
    "\n",
    "For Medication A:\n",
    "SST_A = (10 - 14)^2 + (12 - 14)^2 + (14 - 14)^2 + (11 - 14)^2 + (13 - 14)^2\n",
    "SST_A = 16 + 4 + 0 + 9 + 1\n",
    "SST_A = 30\n",
    "\n",
    "For Medication B:\n",
    "SST_B = (15 - 14)^2 + (17 - 14)^2 + (16 - 14)^2 + (14 - 14)^2 + (18 - 14)^2\n",
    "SST_B = 1 + 9 + 4 + 0 + 16\n",
    "SST_B = 30\n",
    "\n",
    "SST (Total) = SST_A + SST_B\n",
    "SST (Total) = 30 + 30\n",
    "SST (Total) = 60\n",
    "\n",
    "Step 5: Calculate the Sum of Squares Between (SSB):\n",
    "\n",
    "SSB = nA * (XÌ„A - XÌ„G)^2 + nB * (XÌ„B - XÌ„G)^2\n",
    "Where nA and nB are the sample sizes for Medication A and Medication B, respectively.\n",
    "\n",
    "nA = 5 (number of patients in Medication A)\n",
    "nB = 5 (number of patients in Medication B)\n",
    "\n",
    "SSB = 5 * (12 - 14)^2 + 5 * (16 - 14)^2\n",
    "SSB = 5 * (-2)^2 + 5 * (2)^2\n",
    "SSB = 5 * 4 + 5 * 4\n",
    "SSB = 20 + 20\n",
    "SSB = 40\n",
    "\n",
    "Step 6: Calculate the Degrees of Freedom (DF):\n",
    "\n",
    "DF_Total = nTotal - 1\n",
    "Where nTotal is the total number of observations.\n",
    "\n",
    "DF_Total = 10 - 1\n",
    "DF_Total = 9\n",
    "\n",
    "DF_Between = k - 1\n",
    "Where k is the number of groups (in this case, k = 2).\n",
    "\n",
    "DF_Between = 2 - 1\n",
    "DF_Between = 1\n",
    "\n",
    "DF_Residual = DF_Total - DF_Between\n",
    "DF_Residual = 9 - 1\n",
    "DF_Residual = 8\n",
    "\n",
    "Step 7: Calculate the Mean Squares (MS):\n",
    "\n",
    "MS_Between = SSB / DF_Between\n",
    "MS_Between = 40 / 1\n",
    "MS_Between = 40\n",
    "\n",
    "MS_Residual = SST / DF_Residual\n",
    "MS_Residual = 60 / 8\n",
    "MS_Residual = 7.5\n",
    "\n",
    "Step 8: Calculate the F-statistic:\n",
    "\n",
    "F = MS_Between / MS_Residual\n",
    "F = 40 / 7.5\n",
    "F â‰ˆ 5.33\n",
    "\n",
    "Step 9: Look up the critical value of F for your chosen significance level and degrees of freedom. Let's assume we're using a significance level of 0.05 (5%) and degrees of freedom (1, 8).\n",
    "\n",
    "From the F-table or statistical software, the critical value of F at Î± = 0.05 and (1, 8) degrees of freedom is approximately 5.32.\n",
    "\n",
    "Step 10: Compare the calculated F-statistic to the critical value:\n",
    "\n",
    "Since our calculated F-statistic (5.33) is greater than the critical value (5.32), we reject the null hypothesis (H0).\n",
    "\n",
    "Step 11: Interpretation:\n",
    "\n",
    "There is a significant difference in the mean recovery times between Medication A and Medication B based on the ANOVA analysis. The data suggests that one medication is more effective than the other in reducing recovery times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a073f22-168a-4917-9d85-c420ea812304",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10\n",
    "To calculate the 75th percentile of the customer feedback ratings, you first need to sort the data in ascending order and then find the value that corresponds to the 75th percentile. Here's how you can do it step by step:\n",
    "\n",
    "Step 1: Sort the data in ascending order:\n",
    "[6, 7, 7, 8, 8, 8, 8, 9, 9, 10]\n",
    "\n",
    "Step 2: Calculate the position of the 75th percentile:\n",
    "The 75th percentile corresponds to the 75th percent of the data, meaning 75% of the data is below the 75th percentile, and 25% is above it.\n",
    "\n",
    "Percentile Position = (Percentile / 100) * (Number of data points + 1)\n",
    "Percentile Position = (75 / 100) * (10 + 1) = 0.75 * 11 â‰ˆ 8.25\n",
    "\n",
    "Step 3: Determine the value at the 8.25th position:\n",
    "To find the value at the 8.25th position, you can take the average of the 8th and 9th data points since the position is not a whole number.\n",
    "\n",
    "Value at 8th position = 8\n",
    "Value at 9th position = 9\n",
    "\n",
    "Average = (8 + 9) / 2 = 8.5\n",
    "\n",
    "So, the 75th percentile of the customer feedback ratings is approximately 8.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6ed56-71e4-4cf2-b54d-b63870105c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11\n",
    "To perform a hypothesis test to determine if the mean weight differs significantly from 10 grams, we can use a one-sample t-test. The null hypothesis (H0) assumes that the mean weight is equal to 10 grams, while the alternative hypothesis (Ha) assumes that the mean weight is different from 10 grams.\n",
    "\n",
    "Here are the steps to conduct the hypothesis test:\n",
    "\n",
    "Step 1: Define the hypotheses:\n",
    "- Null hypothesis (H0): The population mean weight (Î¼) is equal to 10 grams.\n",
    "- Alternative hypothesis (Ha): The population mean weight (Î¼) is not equal to 10 grams.\n",
    "\n",
    "Step 2: Calculate the sample mean and standard deviation:\n",
    "Let's calculate the sample mean and standard deviation from the given sample of weights.\n",
    "\n",
    "Sample weights: [10.2, 9.8, 10.0, 10.5, 10.3, 10.1]\n",
    "\n",
    "Sample mean (xÌ„) = (10.2 + 9.8 + 10.0 + 10.5 + 10.3 + 10.1) / 6 = 10.17 grams (approx.)\n",
    "\n",
    "Sample standard deviation (s) â‰ˆ 0.26 grams (approx.)\n",
    "\n",
    "Step 3: Set the significance level (Î±):\n",
    "Choose a significance level (Î±) to determine the threshold for the p-value. Let's assume Î± = 0.05 (5%).\n",
    "\n",
    "Step 4: Calculate the t-statistic:\n",
    "The t-statistic can be calculated using the formula:\n",
    "\n",
    "t = (xÌ„ - Î¼) / (s / âˆšn)\n",
    "\n",
    "where xÌ„ is the sample mean, Î¼ is the population mean under the null hypothesis (10 grams), s is the sample standard deviation, and n is the sample size.\n",
    "\n",
    "t = (10.17 - 10) / (0.26 / âˆš6) â‰ˆ 0.17 / 0.1063 â‰ˆ 1.60 (approx.)\n",
    "\n",
    "Step 5: Find the critical value or p-value:\n",
    "Since we are conducting a two-tailed test, we need to find the critical t-value for the given significance level (Î±) and degrees of freedom (df = n - 1). For Î± = 0.05 and df = 5 (6 - 1), the critical t-value is approximately Â±2.571.\n",
    "\n",
    "Alternatively, we can find the p-value corresponding to the calculated t-statistic (1.60) using a t-distribution table or a statistical software. The p-value represents the probability of observing the data, or more extreme results, assuming the null hypothesis is true.\n",
    "\n",
    "Step 6: Make a decision:\n",
    "- If the calculated t-statistic is outside the critical t-value range or if the p-value is less than the significance level (Î±), we reject the null hypothesis (H0) in favor of the alternative hypothesis (Ha).\n",
    "- If the calculated t-statistic is inside the critical t-value range or if the p-value is greater than the significance level (Î±), we fail to reject the null hypothesis (H0).\n",
    "\n",
    "Step 7: Interpret the results:\n",
    "Based on the decision made in Step 6, interpret the results in the context of the problem. If we reject the null hypothesis, it suggests that the mean weight of the product significantly differs from 10 grams. If we fail to reject the null hypothesis, it means there is not enough evidence to conclude that the mean weight significantly differs from 10 grams.\n",
    "\n",
    "Please note that the above calculations and interpretation depend on the sample data and the assumed significance level. Ensure that the data is collected and analyzed accurately to draw valid conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40dcad-982c-4591-96a9-efdeae51699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12\n",
    "To perform a chi-square test to determine if there is a significant difference in the click-through rates between the two designs (Design A and Design B), we need to follow these steps:\n",
    "\n",
    "Step 1: Formulate the null hypothesis (H0) and alternative hypothesis (Ha).\n",
    "Step 2: Calculate the expected frequencies for each category (click-through rates).\n",
    "Step 3: Calculate the chi-square test statistic.\n",
    "Step 4: Determine the degrees of freedom.\n",
    "Step 5: Find the critical value from the chi-square distribution table or use a significance level to find the p-value.\n",
    "Step 6: Compare the test statistic with the critical value or p-value to draw a conclusion about the null hypothesis.\n",
    "\n",
    "Let's go through these steps one by one:\n",
    "\n",
    "Step 1: Formulate the hypotheses:\n",
    "- Null Hypothesis (H0): There is no significant difference in click-through rates between Design A and Design B.\n",
    "- Alternative Hypothesis (Ha): There is a significant difference in click-through rates between Design A and Design B.\n",
    "\n",
    "Step 2: Calculate the expected frequencies:\n",
    "The expected frequency for each category can be calculated as the average of the total click-through rates for each design.\n",
    "\n",
    "Expected Clicks for Design A = (100 + 120 + 110 + 90 + 95) / 5 = 103\n",
    "Expected Clicks for Design B = (80 + 85 + 90 + 95 + 100) / 5 = 90\n",
    "\n",
    "Step 3: Calculate the chi-square test statistic:\n",
    "The chi-square test statistic formula for a 2x2 contingency table (two designs, two categories: clicked, not clicked) is:\n",
    "\n",
    "Ï‡Â² = Î£ [(O - E)Â² / E]\n",
    "\n",
    "where O is the observed frequency and E is the expected frequency.\n",
    "\n",
    "Using the given data:\n",
    "\n",
    "Ï‡Â² = [(100 - 103)Â² / 103] + [(120 - 103)Â² / 103] + [(110 - 103)Â² / 103] + [(90 - 103)Â² / 103] + [(95 - 103)Â² / 103]\n",
    "    + [(80 - 90)Â² / 90] + [(85 - 90)Â² / 90] + [(90 - 90)Â² / 90] + [(95 - 90)Â² / 90] + [(100 - 90)Â² / 90]\n",
    "\n",
    "Ï‡Â² = [9 / 103] + [49 / 103] + [9 / 103] + [169 / 103] + [64 / 103] + [100 / 90] + [25 / 90] + [0] + [25 / 90] + [100 / 90]\n",
    "\n",
    "Ï‡Â² = 0.087 + 0.476 + 0.087 + 1.641 + 0.621 + 1.111 + 0.278 + 0 + 0.278 + 1.111\n",
    "\n",
    "Ï‡Â² â‰ˆ 5.75\n",
    "\n",
    "Step 4: Determine the degrees of freedom:\n",
    "For a 2x2 contingency table, the degrees of freedom (df) is calculated as (number of rows - 1) * (number of columns - 1) = (2 - 1) * (2 - 1) = 1.\n",
    "\n",
    "Step 5: Find the critical value or p-value:\n",
    "At this point, you can either find the critical value from the chi-square distribution table with 1 degree of freedom and a significance level (e.g., Î± = 0.05) or use software/tools to find the p-value associated with the calculated chi-square test statistic.\n",
    "\n",
    "Step 6: Compare the test statistic with the critical value or p-value:\n",
    "If the calculated chi-square test statistic is greater than the critical value or the p-value is less than the significance level (Î±), then we reject the null hypothesis in favor of the alternative hypothesis, which means there is a significant difference in click-through rates between Design A and Design B.\n",
    "\n",
    "Please note that in this example, I haven't provided the critical value or p-value as it requires the specific significance level chosen for the test. If you need that information, you can calculate it using a chi-square table or a statistical software/tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f5282-6e07-4eec-bb92-8df96d4211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q13\n",
    "To calculate the 95% confidence interval for the population mean satisfaction score, you can use the following formula:\n",
    "\n",
    "Confidence Interval = XÌ„ Â± (Z * (Ïƒ/âˆšn))\n",
    "\n",
    "Where:\n",
    "XÌ„ is the sample mean,\n",
    "Z is the critical value from the standard normal distribution corresponding to the desired confidence level (95% confidence level corresponds to a Z-score of approximately 1.96),\n",
    "Ïƒ is the population standard deviation (we'll estimate it using the sample standard deviation),\n",
    "n is the sample size.\n",
    "\n",
    "Let's calculate it step by step:\n",
    "\n",
    "Step 1: Calculate the sample mean (XÌ„):\n",
    "XÌ„ = (7 + 9 + 6 + 8 + 10 + 7 + 8 + 9 + 7 + 8) / 10 = 79 / 10 â‰ˆ 7.9\n",
    "\n",
    "Step 2: Calculate the sample standard deviation (s):\n",
    "s = âˆš[(Î£(xi - XÌ„)Â²) / (n - 1)]\n",
    "   = âˆš[( (7 - 7.9)Â² + (9 - 7.9)Â² + ... + (8 - 7.9)Â²) / (10 - 1)]\n",
    "   = âˆš[(0.81 + 1.21 + ... + 0.01) / 9]\n",
    "   = âˆš[3.7 / 9]\n",
    "   â‰ˆ âˆš0.41111\n",
    "   â‰ˆ 0.6414\n",
    "\n",
    "Step 3: Find the critical value (Z) for the 95% confidence level.\n",
    "For a 95% confidence level, the critical value (Z) is approximately 1.96. You can find this value using a Z-table or a statistical calculator.\n",
    "\n",
    "Step 4: Calculate the standard error (SE):\n",
    "SE = Ïƒ/âˆšn\n",
    "SE â‰ˆ 0.6414 / âˆš10\n",
    "SE â‰ˆ 0.6414 / 3.1623\n",
    "SE â‰ˆ 0.2029\n",
    "\n",
    "Step 5: Calculate the confidence interval:\n",
    "Confidence Interval = XÌ„ Â± (Z * SE)\n",
    "Confidence Interval â‰ˆ 7.9 Â± (1.96 * 0.2029)\n",
    "Confidence Interval â‰ˆ 7.9 Â± 0.398\n",
    "\n",
    "So, the 95% confidence interval for the population mean satisfaction score is approximately 7.502 to 8.298. This means we can be 95% confident that the true population mean satisfaction score falls between these two values based on the given sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b5d13-555d-4aa4-a273-7315b9600d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q14\n",
    "To perform a simple linear regression to predict performance based on temperature, we need to find the best-fitting line that represents the relationship between temperature and performance. The equation of a simple linear regression is:\n",
    "\n",
    "\\[ y = mx + b \\]\n",
    "\n",
    "where:\n",
    "- \\( y \\) is the dependent variable (performance in this case)\n",
    "- \\( x \\) is the independent variable (temperature in degrees Celsius)\n",
    "- \\( m \\) is the slope of the line (represents the change in performance per unit change in temperature)\n",
    "- \\( b \\) is the y-intercept (the value of performance when temperature is 0)\n",
    "\n",
    "Let's calculate the simple linear regression for the given data:\n",
    "\n",
    "Step 1: Calculate the means of temperature and performance:\n",
    "\n",
    "\\[ \\bar{x} = \\frac{20 + 22 + 23 + 19 + 21}{5} = 21 \\]\n",
    "\n",
    "\\[ \\bar{y} = \\frac{8 + 7 + 9 + 6 + 8}{5} = 7.6 \\]\n",
    "\n",
    "Step 2: Calculate the deviations from the mean for both temperature (\\( x \\)) and performance (\\( y \\)):\n",
    "\n",
    "\\[ x_{\\text{dev}} = [20-21, 22-21, 23-21, 19-21, 21-21] = [-1, 1, 2, -2, 0] \\]\n",
    "\n",
    "\\[ y_{\\text{dev}} = [8-7.6, 7-7.6, 9-7.6, 6-7.6, 8-7.6] = [0.4, -0.6, 1.4, -1.6, 0.4] \\]\n",
    "\n",
    "Step 3: Calculate the sum of squares of the deviations:\n",
    "\n",
    "\\[ \\text{SS}_{xx} = \\sum (x_{\\text{dev}})^2 = (-1)^2 + 1^2 + 2^2 + (-2)^2 + 0^2 = 6 \\]\n",
    "\n",
    "\\[ \\text{SS}_{yy} = \\sum (y_{\\text{dev}})^2 = 0.4^2 + (-0.6)^2 + 1.4^2 + (-1.6)^2 + 0.4^2 = 4.4 \\]\n",
    "\n",
    "Step 4: Calculate the sum of cross-products of the deviations:\n",
    "\n",
    "\\[ \\text{SP}_{xy} = \\sum (x_{\\text{dev}} \\times y_{\\text{dev}}) = (-1 \\times 0.4) + (1 \\times -0.6) + (2 \\times 1.4) + (-2 \\times -1.6) + (0 \\times 0.4) = 4 \\]\n",
    "\n",
    "Step 5: Calculate the slope (\\( m \\)) and y-intercept (\\( b \\)):\n",
    "\n",
    "\\[ m = \\frac{\\text{SP}_{xy}}{\\text{SS}_{xx}} = \\frac{4}{6} \\approx 0.67 \\]\n",
    "\n",
    "\\[ b = \\bar{y} - (m \\times \\bar{x}) = 7.6 - (0.67 \\times 21) \\approx 7.6 - 14.07 \\approx -6.47 \\]\n",
    "\n",
    "Step 6: Write the equation of the regression line:\n",
    "\n",
    "\\[ \\text{Performance} = 0.67 \\times \\text{Temperature} - 6.47 \\]\n",
    "\n",
    "So, the simple linear regression equation for predicting performance based on temperature is:\n",
    "\n",
    "\\[ \\text{Performance} = 0.67 \\times \\text{Temperature} - 6.47 \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95fae6-1e20-4177-a3fd-195edbb3214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q15\n",
    "To determine if there is a significant difference in the median preferences between Group A and Group B, we can perform the Mann-Whitney U test. This non-parametric test is used when comparing two independent groups and their data is measured on an ordinal scale (such as the Likert scale in this scenario).\n",
    "\n",
    "The Mann-Whitney U test assesses whether the distributions of the two groups differ significantly. Here are the steps to perform the test:\n",
    "\n",
    "Step 1: Combine the data from both groups and rank the values from lowest to highest.\n",
    "\n",
    "Combined Data (Ranked): [2, 2, 3, 3, 3, 4, 4, 5]\n",
    "\n",
    "Step 2: Assign U values to the ranks. U values are calculated as follows:\n",
    "- For each value in Group A, count how many values in the combined data are smaller than that value (including ties) to get the U value for that value in Group A.\n",
    "- For each value in Group B, count how many values in the combined data are smaller than that value (including ties) to get the U value for that value in Group B.\n",
    "\n",
    "U values for Group A: [5, 3, 7, 1, 5]\n",
    "U values for Group B: [3, 1, 5, 3, 3]\n",
    "\n",
    "Step 3: Calculate the sum of U values for each group.\n",
    "\n",
    "Sum of U values for Group A: 5 + 3 + 7 + 1 + 5 = 21\n",
    "Sum of U values for Group B: 3 + 1 + 5 + 3 + 3 = 15\n",
    "\n",
    "Step 4: Calculate the expected value of U under the null hypothesis of no difference in preferences between the two groups.\n",
    "\n",
    "Expected U = (n1 * n2) / 2\n",
    "\n",
    "where n1 is the sample size of Group A and n2 is the sample size of Group B.\n",
    "\n",
    "Expected U = (5 * 5) / 2 = 25 / 2 = 12.5\n",
    "\n",
    "Step 5: Compare the calculated sum of U values to the expected value of U.\n",
    "\n",
    "Since both groups have small sample sizes (n < 20), we can use the critical values for the Mann-Whitney U test. At the 5% significance level, the critical value for a two-tailed test is 9. If the calculated sum of U values is less than or equal to the critical value, then we reject the null hypothesis and conclude that there is a significant difference in the median preferences between the two groups.\n",
    "\n",
    "In this case, the sum of U values for Group B (15) is greater than the critical value (9). Thus, we fail to reject the null hypothesis and conclude that there is no significant difference in the median preferences between Group A and Group B at the 5% significance level.\n",
    "\n",
    "Note: The Mann-Whitney U test is also known as the Wilcoxon rank-sum test and is a common non-parametric alternative to the independent samples t-test for comparing two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bfa32-e3c6-4b23-9087-aaddb12f7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q16\n",
    "To calculate the interquartile range (IQR) of the ages, we first need to find the first quartile (Q1) and the third quartile (Q3) of the data. The IQR is then the difference between Q3 and Q1.\n",
    "\n",
    "Here are the steps to calculate the IQR:\n",
    "\n",
    "Step 1: Sort the data in ascending order: \n",
    "[25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "\n",
    "Step 2: Find the median (Q2) of the data:\n",
    "Since we have 10 data points, the median is the average of the 5th and 6th values in the sorted list:\n",
    "Median (Q2) = (45 + 50) / 2 = 47.5\n",
    "\n",
    "Step 3: Find Q1 (the first quartile):\n",
    "Since there are 10 data points, Q1 is the median of the first half of the data (excluding the overall median if the number of data points is odd). In our case, the first half of the data is [25, 30, 35, 40, 45], and the median of this set is:\n",
    "Q1 = (30 + 35) / 2 = 32.5\n",
    "\n",
    "Step 4: Find Q3 (the third quartile):\n",
    "Similarly, Q3 is the median of the second half of the data. The second half of the data is [50, 55, 60, 65, 70], and the median of this set is:\n",
    "Q3 = (55 + 60) / 2 = 57.5\n",
    "\n",
    "Step 5: Calculate the IQR:\n",
    "IQR = Q3 - Q1 = 57.5 - 32.5 = 25\n",
    "\n",
    "So, the interquartile range (IQR) of the customer ages is 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4bbc17-d4d1-40fc-961a-0a6f606e12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q17\n",
    "To perform a Kruskal-Wallis test to determine if there is a significant difference in the median accuracy scores between the three algorithms, follow these steps:\n",
    "\n",
    "Step 1: Combine all the accuracy scores from the three algorithms into a single dataset while keeping track of which scores belong to which algorithm.\n",
    "\n",
    "Algorithm A: [0.85, 0.80, 0.82, 0.87, 0.83]\n",
    "Algorithm B: [0.78, 0.82, 0.84, 0.80, 0.79]\n",
    "Algorithm C: [0.90, 0.88, 0.89, 0.86, 0.87]\n",
    "\n",
    "Combined dataset: [0.85, 0.80, 0.82, 0.87, 0.83, 0.78, 0.82, 0.84, 0.80, 0.79, 0.90, 0.88, 0.89, 0.86, 0.87]\n",
    "\n",
    "Step 2: Rank the combined dataset in ascending order.\n",
    "\n",
    "Ranked dataset: [0.78, 0.79, 0.80, 0.80, 0.82, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.87, 0.88, 0.89, 0.90]\n",
    "\n",
    "Step 3: Calculate the ranks for each algorithm separately. If there are tied ranks (i.e., the same value appears more than once), calculate the average rank for those tied values.\n",
    "\n",
    "Algorithm A ranks: [9, 3, 5, 11, 7] (0.85 -> 9, 0.80 -> 3, 0.82 -> 5, 0.87 -> 11, 0.83 -> 7)\n",
    "Algorithm B ranks: [1, 5, 8, 3, 2]  (0.78 -> 1, 0.79 -> 5, 0.80 -> 8, 0.82 -> 3, 0.79 -> 2)\n",
    "Algorithm C ranks: [15, 14, 13, 12, 13] (0.90 -> 15, 0.88 -> 14, 0.89 -> 13, 0.86 -> 12, 0.87 -> 13)\n",
    "\n",
    "Step 4: Calculate the sum of ranks for each algorithm.\n",
    "\n",
    "Sum of ranks for Algorithm A = 9 + 3 + 5 + 11 + 7 = 35\n",
    "Sum of ranks for Algorithm B = 1 + 5 + 8 + 3 + 2 = 19\n",
    "Sum of ranks for Algorithm C = 15 + 14 + 13 + 12 + 13 = 67\n",
    "\n",
    "Step 5: Calculate the Kruskal-Wallis test statistic.\n",
    "\n",
    "Kruskal-Wallis test statistic (H) = [(12 * (35^2 / 5) + 12 * (19^2 / 5) + 12 * (67^2 / 5)) / (15 * (15 + 1))] - 3 * (15 + 1)\n",
    "\n",
    "H = [(12 * (1225) + 12 * (361) + 12 * (4489)) / (15 * 16)] - 3 * 16\n",
    "H = [(14700 + 4332 + 53868) / 240] - 48\n",
    "H = [72900 / 240] - 48\n",
    "H = 303.75 - 48\n",
    "H = 255.75\n",
    "\n",
    "Step 6: Determine the degrees of freedom (df).\n",
    "\n",
    "df = k - 1\n",
    "where k is the number of groups (algorithms) being compared.\n",
    "\n",
    "In this case, k = 3 (Algorithm A, Algorithm B, and Algorithm C).\n",
    "df = 3 - 1 = 2\n",
    "\n",
    "Step 7: Look up the critical value for the Kruskal-Wallis test at the 5% significance level (Î± = 0.05) with df = 2. You can use a Kruskal-Wallis table or a statistical software.\n",
    "\n",
    "For df = 2, the critical value is approximately 5.991.\n",
    "\n",
    "Step 8: Compare the calculated test statistic (H) with the critical value.\n",
    "\n",
    "H = 255.75\n",
    "Critical value = 5.991\n",
    "\n",
    "Since the calculated test statistic (H) is greater than the critical value, we reject the null hypothesis. It indicates that there is a significant difference in the median accuracy scores between the three algorithms based on the Kruskal-Wallis test. Further post-hoc analysis or pairwise comparisons can be conducted to identify which specific algorithms differ significantly from each other in terms of median accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0526f-4621-4161-be7c-4afbd29b7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q18\n",
    "To perform a simple linear regression to predict sales based on price, we need to find the equation of the line that best fits the relationship between price and sales in the given data. The equation of a simple linear regression is of the form: \n",
    "\n",
    "\\[ \\text{Sales} = \\text{Intercept} + \\text{Slope} \\times \\text{Price} \\]\n",
    "\n",
    "where:\n",
    "- Intercept is the value of sales when the price is zero (the point where the line intersects the y-axis).\n",
    "- Slope is the change in sales for a one-unit change in price.\n",
    "\n",
    "Let's calculate the Intercept and Slope using the given data and then create the regression equation.\n",
    "\n",
    "Data:\n",
    "Price (in dollars): [10, 15, 12, 8, 14]\n",
    "Sales: [100, 80, 90, 110, 95]\n",
    "\n",
    "Step 1: Calculate the means of Price and Sales.\n",
    "\\[ \\text{Mean of Price} = \\frac{10 + 15 + 12 + 8 + 14}{5} = \\frac{59}{5} = 11.8 \\]\n",
    "\n",
    "\\[ \\text{Mean of Sales} = \\frac{100 + 80 + 90 + 110 + 95}{5} = \\frac{475}{5} = 95 \\]\n",
    "\n",
    "Step 2: Calculate the deviations from the mean for Price and Sales.\n",
    "\\[ \\text{Deviation of Price} = [10 - 11.8, 15 - 11.8, 12 - 11.8, 8 - 11.8, 14 - 11.8] = [-1.8, 3.2, 0.2, -3.8, 2.2] \\]\n",
    "\n",
    "\\[ \\text{Deviation of Sales} = [100 - 95, 80 - 95, 90 - 95, 110 - 95, 95 - 95] = [5, -15, -5, 15, 0] \\]\n",
    "\n",
    "Step 3: Calculate the sum of products of deviations for Price and Sales.\n",
    "\\[ \\text{Sum of products of deviations} = (-1.8 \\times 5) + (3.2 \\times -15) + (0.2 \\times -5) + (-3.8 \\times 15) + (2.2 \\times 0) \\]\n",
    "\\[ = -9 - 48 - 1 - 57 + 0 = -115 \\]\n",
    "\n",
    "Step 4: Calculate the sum of squares of deviations for Price.\n",
    "\\[ \\text{Sum of squares of deviations of Price} = (-1.8)^2 + (3.2)^2 + (0.2)^2 + (-3.8)^2 + (2.2)^2 \\]\n",
    "\\[ = 3.24 + 10.24 + 0.04 + 14.44 + 4.84 = 32.8 \\]\n",
    "\n",
    "Step 5: Calculate the slope (B):\n",
    "\\[ B = \\frac{\\text{Sum of products of deviations}}{\\text{Sum of squares of deviations of Price}} = \\frac{-115}{32.8} \\approx -3.5061 \\]\n",
    "\n",
    "Step 6: Calculate the intercept (A):\n",
    "\\[ A = \\text{Mean of Sales} - (B \\times \\text{Mean of Price}) \\]\n",
    "\\[ A = 95 - (-3.5061 \\times 11.8) \\approx 133.2957 \\]\n",
    "\n",
    "Step 7: Write the regression equation:\n",
    "\\[ \\text{Sales} = 133.2957 - 3.5061 \\times \\text{Price} \\]\n",
    "\n",
    "So, the regression equation to predict sales based on price is: \\[ \\text{Sales} = 133.2957 - 3.5061 \\times \\text{Price} \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a093b8b-1021-4349-999e-03e7b7a04d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q19\n",
    "To calculate the standard error of the mean satisfaction score, you can follow these steps:\n",
    "\n",
    "Step 1: Find the mean of the data.\n",
    "Step 2: Subtract the mean from each data point and square the result.\n",
    "Step 3: Sum all the squared differences.\n",
    "Step 4: Divide the sum of squared differences by the number of data points (sample size).\n",
    "Step 5: Finally, take the square root of the result.\n",
    "\n",
    "Let's go through the calculations:\n",
    "\n",
    "Step 1: Calculate the mean\n",
    "Mean = (7 + 8 + 9 + 6 + 8 + 7 + 9 + 7 + 8 + 7) / 10\n",
    "Mean = 77 / 10\n",
    "Mean = 7.7\n",
    "\n",
    "Step 2: Subtract the mean from each data point and square the result\n",
    "\n",
    "(7 - 7.7)^2 = (-0.7)^2 = 0.49\n",
    "(8 - 7.7)^2 = (0.3)^2 = 0.09\n",
    "(9 - 7.7)^2 = (1.3)^2 = 1.69\n",
    "(6 - 7.7)^2 = (-1.7)^2 = 2.89\n",
    "(8 - 7.7)^2 = (0.3)^2 = 0.09\n",
    "(7 - 7.7)^2 = (-0.7)^2 = 0.49\n",
    "(9 - 7.7)^2 = (1.3)^2 = 1.69\n",
    "(7 - 7.7)^2 = (-0.7)^2 = 0.49\n",
    "(8 - 7.7)^2 = (0.3)^2 = 0.09\n",
    "(7 - 7.7)^2 = (-0.7)^2 = 0.49\n",
    "\n",
    "Step 3: Sum all the squared differences\n",
    "Sum of squared differences = 0.49 + 0.09 + 1.69 + 2.89 + 0.09 + 0.49 + 1.69 + 0.49 + 0.09 + 0.49\n",
    "Sum of squared differences = 8.51\n",
    "\n",
    "Step 4: Divide the sum of squared differences by the number of data points (sample size)\n",
    "Standard variance = Sum of squared differences / Number of data points\n",
    "Standard variance = 8.51 / 10\n",
    "Standard variance = 0.851\n",
    "\n",
    "Step 5: Take the square root of the result to get the standard error\n",
    "Standard error = âˆš0.851\n",
    "Standard error â‰ˆ 0.922 (rounded to three decimal places)\n",
    "\n",
    "So, the standard error of the mean satisfaction score is approximately 0.922."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5496820-1604-40d6-ad86-54c6595094eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.767\n",
      "Model:                            OLS   Adj. R-squared:                  0.689\n",
      "Method:                 Least Squares   F-statistic:                     9.872\n",
      "Date:                Wed, 19 Jul 2023   Prob (F-statistic):             0.0516\n",
      "Time:                        17:35:30   Log-Likelihood:                -9.5288\n",
      "No. Observations:                   5   AIC:                             23.06\n",
      "Df Residuals:                       3   BIC:                             22.28\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  12.2012      4.429      2.755      0.070      -1.893      26.296\n",
      "Advertising Expenditure     1.1524      0.367      3.142      0.052      -0.015       2.320\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.136\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.546\n",
      "Skew:                          -0.267   Prob(JB):                        0.761\n",
      "Kurtosis:                       1.471   Cond. No.                         57.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "#Q20\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "data = {\n",
    "    'Advertising Expenditure': [10, 15, 12, 8, 14],\n",
    "    'Sales': [25, 30, 28, 20, 26]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Intercept'] = 1\n",
    "X = df[['Intercept', 'Advertising Expenditure']]\n",
    "y = df['Sales']\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41674210-5dbb-48c1-ab12-d137883b6116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
